# train$mpg01 = as.factor(train$mpg01)
lda.fit <- lda(mpg01~cylinders+weight+displacement+horsepower, data = mpg, subset = train) # ???
train = (mpg$year %% 2 == 0)
test = (mpg$year %% 2 != 0)
# mpg$cylinders = as.numeric(mpg$cylinders)
# train$cylinders = as.factor(train$cylinders)
# train$cylinders = as.factor(train$horsepower)
# train$mpg01 = as.factor(train$mpg01)
lda.fit <- lda(mpg01~cylinders+weight+displacement+horsepower, data = mpg, subset = train) # ???
logistic.fit <- glm(mpg01~cylinders+weight+displacement+horsepower, data = mpg, family = binomial)
logistic.pred <- predict(logistic.fit, type="response")
pred <- ifelse(logistic.pred>0.5, 1, 0)
table(mpg$mpg01, pred)
logistic.fit <- glm(mpg01~cylinders+weight+displacement+horsepower, data = mpg, family = binomial, subset = train)
logistic.pred <- predict(logistic.fit, type="response")
pred <- ifelse(logistic.pred>0.5, 1, 0)
table(mpg$mpg01, pred)
logistic.pred <- predict(logistic.fit, testXy, type="response")
pred <- ifelse(logistic.pred>0.5, 1, 0)
table(mpg$mpg01, pred)
logistic.pred <- predict(logistic.fit, mpg[test,], type="response")
# Lab 2
default <- read.table(read.csv("data/data/default.txt"))
# Lab 2
default <- read.table(read.csv("data/data/data/default.txt"))
# Lab 2
default <- read.table("data/data/data/default.txt")
head(default)
# Lab 2
Default <- read.table("data/data/data/default.txt")
head(Default)
def_glm.fit <- glm(default~income+balance, data = Default, family = binomial)
summary(def_glm.fit)
boot.fn <- function(dat, idx){
my_glm <- glm(default~income+balance, date = dat, family = binomial, subset = idx)
coeff <- coef(my_glm)
return(coeff)
}
library(boot)
boot(Default, 50)
boot(Default, boot.fn, 50)
head(Default)
?boot
boot.fn <- function(dat, idx){
my_glm <- glm(default~income+balance, date = dat, family = binomial, subset = idx)
coeff <- coef(my_glm)
return(coeff)
}
library(boot)
boot(Default, boot.fn, 50)
Default
boot.fn = function(data, index){
return(coef(glm(default ~ income + balance, data = data,
family =binomial, subset = index)))
}
library(boot)
boot(Default, boot.fn, 50)
boot.fn = function(dat, index){
return(coef(glm(default ~ income + balance, data = dat,
family =binomial, subset = index)))
}
library(boot)
boot(Default, boot.fn, 50)
boot.fn = function(dat, indx){
return(coef(glm(default ~ income + balance, data = dat,
family =binomial, subset = indx)))
}
library(boot)
boot(Default, boot.fn, 50)
boot.fn <- function(dat, idx){
my_glm <- glm(default~income+balance, data = dat, family = binomial, subset = idx)
coeff <- coef(my_glm)
return(coeff)
}
library(boot)
boot(Default, boot.fn, 50)
opts_chunk$set(eval=TRUE, cache=TRUE, fig.width=7, fig.height=4)
library(tidyverse)
opts_chunk$set(eval=TRUE, cache=TRUE, fig.width=7, fig.height=4)
library(knitr)
opts_chunk$set(eval=TRUE, cache=TRUE, fig.width=7, fig.height=4)
auto = read.csv("data/Auto.csv", header = T)
head(auto)
auto$horsepower <- as.numeric(auto$horsepower)
head(auto)
library(ISLR)
nrow(auto)
trainIdx = sample(397, 198)
lm.fit <- lm(mpg~horsepower, data = auto, subset=train)
lm.pred <- predict(lm.fit, auto[-train,])
lm.pred
mean((mpg$mpg - lm.pred)^2)
mean((mpg[-train,]$mpg - lm.pred)^2)
library(leaps)
install.packages("leaps")
regfit.full <- regsubsets(Salary~., Hitters)
??regsubsets
library(leaps)
regfit.full <- regsubsets(Salary~., Hitters)
data("Hitters")
data(Hitters)
library(ISLR)
regfit.full <- regsubsets(Salary~., Hitters)
summary(regfit.full)
head(Hitters)
# forward
regfit.full <- regsubsets(Salary~., Hitters, nvmax = 19, method = 'forward')
summary(regfit.full)
reg.summary <- summary(regfit.full)
names(reg.summary)
oldpar <- par()
par(mfrow = c(2,2))
plot(reg.summary$rss)
plot(reg.summary$adjr2)
plot(reg.summary$cp)
plot(reg.summary$bic)
which.max(reg.summary$adjr2)
plot(
reg.summary$adjr2
argmax_adjr2 <- which.max(reg.summary$adjr2)
par(mfrow = c(2,2))
plot(reg.summary$rss)
plot(reg.summary$adjr2)
argmax_adjr2 <- which.max(reg.summary$adjr2)
points(argmax_adjr2, reg.summary$adjr2[argmax_adjr2])
points(argmax_adjr2, reg.summary$adjr2[argmax_adjr2], col = "red")
?points
points(argmax_adjr2, reg.summary$adjr2[argmax_adjr2], col = "red", pch = 24, cex = 5)
points(argmax_adjr2, reg.summary$adjr2[argmax_adjr2], col = "red", pch = 22, cex = 5)
points(argmax_adjr2, reg.summary$adjr2[argmax_adjr2], col = "red", pch = 12, cex = 5)
points(argmax_adjr2, reg.summary$adjr2[argmax_adjr2], col = "red", pch = 12, cex = 3)
library(glmnet)
install.packages("glmnet")
library(ISLR)
library(glmnet)
Hitters
Hitters <- na.omit(Hitters)
dim(Hitters)
x = model.matrix(Salary~., Hitters)
x
head(Hitters)
y = Hitters$Salary
n = 263
B = 1000
best = matrix(0, B, 20)
best
for (b in (1:B)){
bid = sample(n,n, replace = TRUE)
bx = x[bid,]
by = y[,bid]
grid = 10^seq(4, -1, length.out = 100)
cv.out = cv.glmnet(bx, by, alpha = 1, lambda = grid)
blamb = cv.out$lambda.min
lasso.mod = glmnet(bx,by, alpha = 1, lambda = exp(blamb))
best[b,] = as.vector(coef(lasso.mod))
cat("\t b=")
cat(b)
}
for (b in (1:B)){
bid = sample(n,n, replace = TRUE)
bx = x[bid,]
by = y[bid]
grid = 10^seq(4, -1, length.out = 100)
cv.out = cv.glmnet(bx, by, alpha = 1, lambda = grid)
blamb = cv.out$lambda.min
lasso.mod = glmnet(bx,by, alpha = 1, lambda = exp(blamb))
best[b,] = as.vector(coef(lasso.mod))
cat("\t b=")
cat(b)
}
dim(Hitters)
attach(Hitters)
x = model.matrix(Salary~., Hitters)
x
y = Hitters$Salary
n = 263
B = 1000
best = matrix(0, B, 20)
for (b in (1:B)){
bid = sample(n,n, replace = TRUE)
bx = x[bid,]
by = y[bid]
grid = 10^seq(4, -1, length.out = 100)
cv.out = cv.glmnet(bx, by, alpha = 1, lambda = grid)
blamb = cv.out$lambda.min
lasso.mod = glmnet(bx,by, alpha = 1, lambda = exp(blamb))
best[b,] = as.vector(coef(lasso.mod))
cat("\t b=")
cat(b)
}
bid = sample(n,n, replace = TRUE)
bx = x[bid,]
by = y[bid]
grid = 10^seq(4, -1, length.out = 100)
cv.out = cv.glmnet(bx, by, alpha = 1, lambda = grid)
blamb = cv.out$lambda.min
lasso.mod = glmnet(bx,by, alpha = 1, lambda = exp(blamb))
best[b,] = as.vector(coef(lasso.mod))
lasso.mod
coef(lasso.mod)
best[b,] = (coef(lasso.mod))
cat("\t b=")
cat(b)
for (b in (1:B)){
bid = sample(n,n, replace = TRUE)
bx = x[bid,]
by = y[bid]
grid = 10^seq(4, -1, length.out = 100)
cv.out = cv.glmnet(bx, by, alpha = 1, lambda = grid)
blamb = cv.out$lambda.min
lasso.mod = glmnet(bx,by, alpha = 1, lambda = exp(blamb))
best[b,] = (coef(lasso.mod))
cat("\t b=")
cat(b)
}
grid
blamb
which(grid == blamb)
grid[70]
as.vector(coef(lasso.mod))
best = matrix(0, B, 21)
for (b in (1:B)){
bid = sample(n,n, replace = TRUE)
bx = x[bid,]
by = y[bid]
grid = 10^seq(4, -1, length.out = 100)
cv.out = cv.glmnet(bx, by, alpha = 1, lambda = grid)
blamb = cv.out$lambda.min
lasso.mod = glmnet(bx,by, alpha = 1, lambda = exp(blamb))
best[b,] = as.vector(coef(lasso.mod))
cat("\t b=")
cat(b)
}
best
mu <- apply(best, 2, mean)
mu
se <- apply(best, 2, sd)
se
?sd
tstat <- mu/se
tstat
pvalue <- 2*(1-pnorm(abs(tstat)))
pvalue
select <- (best != 0)
select
stab <- apply(select, 2, sum)/B
stab
numselect <- apply(select, 1, sum)
hist(numselect)
hist(numselect, breaks = 20)
?abline
?lm
?plot
advertising = read.csv('data/Advertising.csv', row.names = NULL)
lm.fit <- lm(sales ~ TV, data = advertising)
summary(lm.fit)
head(Credit)
lm.fit <- lm(Balance~Gender, Credit)
summary(lm.fit)
attach(Credit)
plot(Balance~Income, col = Gender)
lm.fit <- lm(Balance~Income+Gender)
lm.fit$coefficients
mylm <- lm(Balance~., data = Credit)
summary(mylm)
aic.credit <- stepAIC(mylm, direction = "both")
summary(aic.credit)
library(datasets)
library(MASS)
library(ISLR)
advertising = read.csv('data/Advertising.csv', row.names = NULL)
lm.fit <- lm(sales ~ TV, data = advertising)
summary(lm.fit)
head(Credit)
lm.fit <- lm(Balance~Gender, Credit)
summary(lm.fit)
attach(Credit)
plot(Balance~Income, col = Gender)
lm.fit <- lm(Balance~Income+Gender)
lm.fit$coefficients
mylm <- lm(Balance~., data = Credit)
summary(mylm)
aic.credit <- stepAIC(mylm, direction = "both")
summary(aic.credit)
library(pdflatex)
install.packages("latexpdf")
install.packages("lpdfatex")
install.packages("pdflatex")
library(latexpdf)
library(ISLR)
attach(Wage)
fit <- lm(wage~poly(age, 4), data = Wage)
coef(summary(fit))
fit2=lm(wage~poly(age,4,raw=T),data=Wage)
coef(summary(fit2))
?poly
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
par(mfrow=c(1,2),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
par(mfrow=c(1,2),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
fit=glm(I(wage>250)~poly(age,4),data=Wage,family=binomial)
preds=predict(fit,newdata=list(age=age.grid),se=T)
pfit=exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))
preds=predict(fit,newdata=list(age=age.grid),type="response",se=T)
plot(age,I(wage>250),xlim=agelims,type="n",ylim=c(0,.2))
points(jitter(age), I((wage>250)/5),cex=.5,pch="|",col="darkgrey")
lines(age.grid,pfit,lwd=2, col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
# spline
library(splines)
fit=lm(wage~bs(age,knots=c(25,40,60)),data=Wage)
pred=predict(fit,newdata=list(age=age.grid),se=T)
plot(age,wage,col="gray")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
fit2=lm(wage~ns(age,df=4),data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid),se=T)
lines(age.grid, pred2$fit,col="red",lwd=2)
par(mfrow=c(1,1))
plot(age,wage,col="gray")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
fit2=lm(wage~ns(age,df=4),data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid),se=T)
lines(age.grid, pred2$fit,col="red",lwd=2)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Smoothing Spline")
fit=smooth.spline(age,wage,df=16)
fit2=smooth.spline(age,wage,cv=TRUE)
fit2$df
lines(fit,col="red",lwd=2)
lines(fit2,col="blue",lwd=2)
legend("topright",legend=c("16 DF","6.8 DF"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
par() <- oldpar
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Local Regression")
fit=loess(wage~age,span=.2,data=Wage)
fit2=loess(wage~age,span=.5,data=Wage)
lines(age.grid,predict(fit,data.frame(age=age.grid)),col="red",lwd=2)
lines(age.grid,predict(fit2,data.frame(age=age.grid)),col="blue",lwd=2)
legend("topright",legend=c("Span=0.2","Span=0.5"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
library(ISLR)
attach(Wage)
fit <- lm(wage~poly(age, 4), data = Wage)
coef(summary(fit))
fit2=lm(wage~poly(age,4,raw=T),data=Wage) # use raw (not orthogonal) polynomials
coef(summary(fit2))
# polynomial regression
oldpar <- par()
par(mfrow=c(1,2),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
# plot1
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
# plot2
fit=glm(I(wage>250)~poly(age,4),data=Wage,family=binomial)
preds=predict(fit,newdata=list(age=age.grid),se=T)
pfit=exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))
preds=predict(fit,newdata=list(age=age.grid),type="response",se=T)
plot(age,I(wage>250),xlim=agelims,type="n",ylim=c(0,.2))
points(jitter(age), I((wage>250)/5),cex=.5,pch="|",col="darkgrey")
lines(age.grid,pfit,lwd=2, col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
# spline
library(splines)
fit=lm(wage~bs(age,knots=c(25,40,60)),data=Wage)
pred=predict(fit,newdata=list(age=age.grid),se=T)
plot(age,wage,col="gray")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
fit2=lm(wage~ns(age,df=4),data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid),se=T)
lines(age.grid, pred2$fit,col="red",lwd=2)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Smoothing Spline")
fit=smooth.spline(age,wage,df=16)
fit2=smooth.spline(age,wage,cv=TRUE)
fit2$df
lines(fit,col="red",lwd=2)
lines(fit2,col="blue",lwd=2)
legend("topright",legend=c("16 DF","6.8 DF"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Local Regression")
fit=loess(wage~age,span=.2,data=Wage)
fit2=loess(wage~age,span=.5,data=Wage)
lines(age.grid,predict(fit,data.frame(age=age.grid)),col="red",lwd=2)
lines(age.grid,predict(fit2,data.frame(age=age.grid)),col="blue",lwd=2)
legend("topright",legend=c("Span=0.2","Span=0.5"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
par() <- oldpar
library(gam)
install.packages("gam")
gam1=lm(wage~ns(year,4)+ns(age,5)+education,data=Wage)
library(gam)
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
plot.gam(gam1, se=TRUE, col="red")
gam.m1=gam(wage~s(age,5)+education,data=Wage)
gam.m2=gam(wage~year+s(age,5)+education,data=Wage)
anova(gam.m1,gam.m2,gam.m3,test="F")
summary(gam.m3)
preds=predict(gam.m2,newdata=Wage)
gam.lo=gam(wage~s(year,df=4)+lo(age,span=0.7)+education,data=Wage)
plot.gam(gam.lo, se=TRUE, col="green")
gam.lo.i=gam(wage~lo(year,age,span=0.5)+education,data=Wage)
library(akima)
plot(gam.lo.i)
gam.lr=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage)
par(mfrow=c(1,3))
plot(gam.lr,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!="1. < HS plot(gam.lr.s,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!=" < HS Grad"))
plot(gam.lr.s,se=T,col="green")
gam1=lm(wage~ns(year,4)+ns(age,5)+education,data=Wage)
library(gam)
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
plot.gam(gam1, se=TRUE, col="red")
?plot.Gam
source('C:/Users/renz/Desktop/SNU/통계적 빅데이터 학습이론/CH07_npreg.R', echo=TRUE)
plot.Gam(gam1, se=TRUE, col="red")
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
plot.Gam(gam1, se=TRUE, col="red")
gam.m1=gam(wage~s(age,5)+education,data=Wage)
gam.m2=gam(wage~year+s(age,5)+education,data=Wage)
anova(gam.m1,gam.m2,gam.m3,test="F")
summary(gam.m3)
preds=predict(gam.m2,newdata=Wage)
gam.lo=gam(wage~s(year,df=4)+lo(age,span=0.7)+education,data=Wage)
plot.gam(gam.lo, se=TRUE, col="green")
plot.Gam(gam.lo, se=TRUE, col="green")
gam.lo.i=gam(wage~lo(year,age,span=0.5)+education,data=Wage)
library(akima)
plot(gam.lo.i)
install.packages("akima")
library(akima)
plot(gam.lo.i)
gam.lr=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage)
par(mfrow=c(1,3))
plot(gam.lr,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!=" < HS Grad"))
plot(gam.lr.s,se=T,col="green")
par() <- oldpar
library(ISLR)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
plot(x)
par(mfrow=c(1,1))
plot(x)
plot(x)
km.out <- kmeans(x, 2, nstart = 20)
plot(x, col=(km.out$cluster+1),main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)
km.out
set.seed(3)
km.out <- kmeans(x, 3, nstart = 1)
km.out$tot.withinss
km <- vector()
for (i in 1:10){
km.out <- kmeans(x, i, nstart = 10)
km[i] <- km.out$tot.withinss
}
km
plot(km, type = 'l')
points(km, col = "red")
points(km, col = "red", cex = 1.5)

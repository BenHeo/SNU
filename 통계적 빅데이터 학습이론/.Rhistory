tstat
pvalue <- 2*(1-pnorm(abs(tstat)))
pvalue
select <- (best != 0)
select
stab <- apply(select, 2, sum)/B
stab
numselect <- apply(select, 1, sum)
hist(numselect)
hist(numselect, breaks = 20)
?abline
?lm
?plot
advertising = read.csv('data/Advertising.csv', row.names = NULL)
lm.fit <- lm(sales ~ TV, data = advertising)
summary(lm.fit)
head(Credit)
lm.fit <- lm(Balance~Gender, Credit)
summary(lm.fit)
attach(Credit)
plot(Balance~Income, col = Gender)
lm.fit <- lm(Balance~Income+Gender)
lm.fit$coefficients
mylm <- lm(Balance~., data = Credit)
summary(mylm)
aic.credit <- stepAIC(mylm, direction = "both")
summary(aic.credit)
library(datasets)
library(MASS)
library(ISLR)
advertising = read.csv('data/Advertising.csv', row.names = NULL)
lm.fit <- lm(sales ~ TV, data = advertising)
summary(lm.fit)
head(Credit)
lm.fit <- lm(Balance~Gender, Credit)
summary(lm.fit)
attach(Credit)
plot(Balance~Income, col = Gender)
lm.fit <- lm(Balance~Income+Gender)
lm.fit$coefficients
mylm <- lm(Balance~., data = Credit)
summary(mylm)
aic.credit <- stepAIC(mylm, direction = "both")
summary(aic.credit)
library(pdflatex)
install.packages("latexpdf")
install.packages("lpdfatex")
install.packages("pdflatex")
library(latexpdf)
library(ISLR)
attach(Wage)
fit <- lm(wage~poly(age, 4), data = Wage)
coef(summary(fit))
fit2=lm(wage~poly(age,4,raw=T),data=Wage)
coef(summary(fit2))
?poly
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
par(mfrow=c(1,2),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
par(mfrow=c(1,2),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
fit=glm(I(wage>250)~poly(age,4),data=Wage,family=binomial)
preds=predict(fit,newdata=list(age=age.grid),se=T)
pfit=exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))
preds=predict(fit,newdata=list(age=age.grid),type="response",se=T)
plot(age,I(wage>250),xlim=agelims,type="n",ylim=c(0,.2))
points(jitter(age), I((wage>250)/5),cex=.5,pch="|",col="darkgrey")
lines(age.grid,pfit,lwd=2, col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
# spline
library(splines)
fit=lm(wage~bs(age,knots=c(25,40,60)),data=Wage)
pred=predict(fit,newdata=list(age=age.grid),se=T)
plot(age,wage,col="gray")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
fit2=lm(wage~ns(age,df=4),data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid),se=T)
lines(age.grid, pred2$fit,col="red",lwd=2)
par(mfrow=c(1,1))
plot(age,wage,col="gray")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
fit2=lm(wage~ns(age,df=4),data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid),se=T)
lines(age.grid, pred2$fit,col="red",lwd=2)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Smoothing Spline")
fit=smooth.spline(age,wage,df=16)
fit2=smooth.spline(age,wage,cv=TRUE)
fit2$df
lines(fit,col="red",lwd=2)
lines(fit2,col="blue",lwd=2)
legend("topright",legend=c("16 DF","6.8 DF"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
par() <- oldpar
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Local Regression")
fit=loess(wage~age,span=.2,data=Wage)
fit2=loess(wage~age,span=.5,data=Wage)
lines(age.grid,predict(fit,data.frame(age=age.grid)),col="red",lwd=2)
lines(age.grid,predict(fit2,data.frame(age=age.grid)),col="blue",lwd=2)
legend("topright",legend=c("Span=0.2","Span=0.5"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
library(ISLR)
attach(Wage)
fit <- lm(wage~poly(age, 4), data = Wage)
coef(summary(fit))
fit2=lm(wage~poly(age,4,raw=T),data=Wage) # use raw (not orthogonal) polynomials
coef(summary(fit2))
# polynomial regression
oldpar <- par()
par(mfrow=c(1,2),mar=c(4.5,4.5,1,1),oma=c(0,0,4,0))
# plot1
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Degree-4 Polynomial",outer=T)
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
preds2=predict(fit2,newdata=list(age=age.grid),se=TRUE)
max(abs(preds$fit-preds2$fit))
# plot2
fit=glm(I(wage>250)~poly(age,4),data=Wage,family=binomial)
preds=predict(fit,newdata=list(age=age.grid),se=T)
pfit=exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))
preds=predict(fit,newdata=list(age=age.grid),type="response",se=T)
plot(age,I(wage>250),xlim=agelims,type="n",ylim=c(0,.2))
points(jitter(age), I((wage>250)/5),cex=.5,pch="|",col="darkgrey")
lines(age.grid,pfit,lwd=2, col="blue")
matlines(age.grid,se.bands,lwd=1,col="blue",lty=3)
# spline
library(splines)
fit=lm(wage~bs(age,knots=c(25,40,60)),data=Wage)
pred=predict(fit,newdata=list(age=age.grid),se=T)
plot(age,wage,col="gray")
lines(age.grid,pred$fit,lwd=2)
lines(age.grid,pred$fit+2*pred$se,lty="dashed")
lines(age.grid,pred$fit-2*pred$se,lty="dashed")
dim(bs(age,knots=c(25,40,60)))
dim(bs(age,df=6))
attr(bs(age,df=6),"knots")
fit2=lm(wage~ns(age,df=4),data=Wage)
pred2=predict(fit2,newdata=list(age=age.grid),se=T)
lines(age.grid, pred2$fit,col="red",lwd=2)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Smoothing Spline")
fit=smooth.spline(age,wage,df=16)
fit2=smooth.spline(age,wage,cv=TRUE)
fit2$df
lines(fit,col="red",lwd=2)
lines(fit2,col="blue",lwd=2)
legend("topright",legend=c("16 DF","6.8 DF"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
plot(age,wage,xlim=agelims,cex=.5,col="darkgrey")
title("Local Regression")
fit=loess(wage~age,span=.2,data=Wage)
fit2=loess(wage~age,span=.5,data=Wage)
lines(age.grid,predict(fit,data.frame(age=age.grid)),col="red",lwd=2)
lines(age.grid,predict(fit2,data.frame(age=age.grid)),col="blue",lwd=2)
legend("topright",legend=c("Span=0.2","Span=0.5"),col=c("red","blue"),lty=1,lwd=2,cex=.8)
par() <- oldpar
library(gam)
install.packages("gam")
gam1=lm(wage~ns(year,4)+ns(age,5)+education,data=Wage)
library(gam)
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
plot.gam(gam1, se=TRUE, col="red")
gam.m1=gam(wage~s(age,5)+education,data=Wage)
gam.m2=gam(wage~year+s(age,5)+education,data=Wage)
anova(gam.m1,gam.m2,gam.m3,test="F")
summary(gam.m3)
preds=predict(gam.m2,newdata=Wage)
gam.lo=gam(wage~s(year,df=4)+lo(age,span=0.7)+education,data=Wage)
plot.gam(gam.lo, se=TRUE, col="green")
gam.lo.i=gam(wage~lo(year,age,span=0.5)+education,data=Wage)
library(akima)
plot(gam.lo.i)
gam.lr=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage)
par(mfrow=c(1,3))
plot(gam.lr,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!="1. < HS plot(gam.lr.s,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!=" < HS Grad"))
plot(gam.lr.s,se=T,col="green")
gam1=lm(wage~ns(year,4)+ns(age,5)+education,data=Wage)
library(gam)
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
plot.gam(gam1, se=TRUE, col="red")
?plot.Gam
source('C:/Users/renz/Desktop/SNU/통계적 빅데이터 학습이론/CH07_npreg.R', echo=TRUE)
plot.Gam(gam1, se=TRUE, col="red")
gam.m3=gam(wage~s(year,4)+s(age,5)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam.m3, se=TRUE,col="blue")
plot.Gam(gam1, se=TRUE, col="red")
gam.m1=gam(wage~s(age,5)+education,data=Wage)
gam.m2=gam(wage~year+s(age,5)+education,data=Wage)
anova(gam.m1,gam.m2,gam.m3,test="F")
summary(gam.m3)
preds=predict(gam.m2,newdata=Wage)
gam.lo=gam(wage~s(year,df=4)+lo(age,span=0.7)+education,data=Wage)
plot.gam(gam.lo, se=TRUE, col="green")
plot.Gam(gam.lo, se=TRUE, col="green")
gam.lo.i=gam(wage~lo(year,age,span=0.5)+education,data=Wage)
library(akima)
plot(gam.lo.i)
install.packages("akima")
library(akima)
plot(gam.lo.i)
gam.lr=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage)
par(mfrow=c(1,3))
plot(gam.lr,se=T,col="green")
table(education,I(wage>250))
gam.lr.s=gam(I(wage>250)~year+s(age,df=5)+education,family=binomial,data=Wage,subset=(education!=" < HS Grad"))
plot(gam.lr.s,se=T,col="green")
par() <- oldpar
library(ISLR)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
plot(x)
par(mfrow=c(1,1))
plot(x)
plot(x)
km.out <- kmeans(x, 2, nstart = 20)
plot(x, col=(km.out$cluster+1),main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)
km.out
set.seed(3)
km.out <- kmeans(x, 3, nstart = 1)
km.out$tot.withinss
km <- vector()
for (i in 1:10){
km.out <- kmeans(x, i, nstart = 10)
km[i] <- km.out$tot.withinss
}
km
plot(km, type = 'l')
points(km, col = "red")
points(km, col = "red", cex = 1.5)
library(ISLR)
library(datasets)
library(tidyverse)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
plot(x)
km.out <- kmeans(x, 2, nstart = 20)
plot(x, col=(km.out$cluster+1),main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)
km.out
set.seed(3)
km <- vector()
for (i in 1:10){
km.out <- kmeans(x, i, nstart = 10)
km[i] <- km.out$tot.withinss
}
km
plot(km, type = 'l')
points(km, col = "red", cex = 1.5)
ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point(size = 2)
irisCluster <- kmeans(iris[,c(3,4)], 3, nstart = 20)
table(iris$Species, irisCluster$cluster)
x = iris[,c(3,4)]
hc.complete <- hclust(dist(x), "complete") # dist is essential
hc.average <- hclust(dist(x), "average") # dist is essential
hc.single <- hclust(dist(x), "single") # dist is essential
plot(hc.complete, main = "Complete Clustering", xlab = "", ylab = "", cex = 0.9)
plot(hc.average, main = "Average Clustering", xlab = "", ylab = "", cex = 0.9)
plot(hc.single, main = "Single Clustering", xlab = "", ylab = "", cex = 0.9)
cutree(hc.complete, 2)
cutree(hc.complete, 3)
hcc_iris <- cutree(hc.complete, 3)
table(iris$Species, hcc_iris)
load("data/AlzheimerDisease/AlzheimerDisease.RData")
head(predictors)
train.x=predictors[1:250,1:129]
test.x=predictors[251:333,1:129]
train.y=as.numeric(diagnosis[1:250])
test.y=as.numeric(diagnosis[251:333])
pr.out <- prcomp(train.x, scale = TRUE)
pr.out
str(pr.out)
pr.out$rotation
dim(pr.out$x)
str(pr.out$x)
biplot(pr.out, scale = 0, cex = 0.5)
pr.out$rotation
pr.out$sdev
pr.out$sdev[1:10]
pr.var <- pr.out$sdev[1:10]^2
pr.var
pve <- pr.var/sum(pr.var)
pve
pr.var <- pr.out$sdev^2
pr.var[1:10]
pve[1:10]
sum(pr.var)
pr.var
pve <- pr.var/sum(pr.var)
sum(pve)
plot(pvep[1:30], xlab="Principal Component",
ylab="Proportion of Variance Explained", ylim=c(0,0.3),type='b')
plot(pve[1:30], xlab="Principal Component",
ylab="Proportion of Variance Explained", ylim=c(0,0.3),type='b')
plot(pr.out$rotation[,1], pr.out$rotation[,2])
USArrests
x0=USArrests
set.seed(1)
x5=USArrests[,2]+rnorm(50,0.01)
x=cbind(x0,x5)
x=scale(x)
x
y=1+1*x[1]+2*x[2]+3*x[3]+4*x[4]+5*x[5]+rnorm(50)
pr.out=prcomp(x,scale=T)
head(pr.out,n=1)
head(pr.out,n=2)
x=cbind(x0,new = x5)
x
x=scale(x)
y=1+1*x[1]+2*x[2]+3*x[3]+4*x[4]+5*x[5]+rnorm(50)
pr.out=prcomp(x,scale=T)
head(pr.out,n=2)
x[1]
x[2]
x
x[1]
x[2]
str(x)
y=1+1*x[,1]+2*x[,2]+3*x[,3]+4*x[,4]+5*x[,5]+rnorm(50)
y
pr.out=prcomp(x,scale=T)
head(pr.out,n=2)
pcscore=pr.out$x[,1:2] #2개의 principal component 사용
load=pr.out$rotation[,1:2]
plm=lm(unlist(y)~pcscore)
pbeta=plm$coef
betaest=rep(0,6)
betaest[1]=pbeta[1]
for(k in (2:6)){
betaest[k]=pbeta[2]*load[k-1,1]+pbeta[3]*load[k-1,2]
}
for(k in (2:6)){
betaest[k]=pbeta[2]*load[k-1,1]
}
betaest
library(pls)
install.packages("pls")
library(ISLR)
library(datasets)
library(tidyverse)
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
plot(x)
km.out <- kmeans(x, 2, nstart = 20)
plot(x, col=(km.out$cluster+1),main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)
km.out
set.seed(3)
km <- vector()
for (i in 1:10){
km.out <- kmeans(x, i, nstart = 10)
km[i] <- km.out$tot.withinss
}
km
plot(km, type = 'l')
points(km, col = "red", cex = 1.5)
mu_km <- mean(km)
std_km <- sd(km)
lines(mu_km+std_km)
ablines(mu_km+std_km)
abline(mu_km+std_km)
abline(x=1:10, y=mu_km+std_km)
mu_km
std_km
km
lines(x=1:10, y=mu_km+std_km)
ablines(x=1:10, y=mu_km+std_km)
abline(x=1:10, y=mu_km+std_km)
abline(h=mu_km+std_km)
abline(h=mu_km-std_km)
mu_km <- mean(km[5:10])
std_km <- sd(km[5:10])
abline(h=mu_km+std_km)
abline(h=mu_km-std_km)
plot(km, type = 'l')
points(km, col = "red", cex = 1.5)
mu_km <- mean(km[5:10])
std_km <- sd(km[5:10])
abline(h=mu_km+std_km)
abline(h=mu_km-std_km)
plot(km, type = 'l')
points(km, col = "red", cex = 1.5)
mu_km <- mean(km[4:10])
std_km <- sd(km[4:10])
abline(h=mu_km+std_km)
abline(h=mu_km-std_km)
plot(km, type = 'l')
points(km, col = "red", cex = 1.5)
mu_km <- mean(km[4:10])
std_km <- sd(km[4:10])
abline(h=mu_km+2*std_km)
abline(h=mu_km-2*std_km)
plot(km, type = 'l')
points(km, col = "red", cex = 1.5)
mu_km <- mean(km[2:10])
std_km <- sd(km[2:10])
abline(h=mu_km+2*std_km)
abline(h=mu_km-2*std_km)
View(dist(x))
x = iris[,c(3,4)]
View(dist(x))
x0=USArrests
set.seed(1)
x5=USArrests[,2]+rnorm(50,0.01)
colMeans(USArrests)
pr.out$sdev^2
var_pr <- pr.out$sdev^2
t_var_pr <- sum(var_pr)
var_pr/t_var_pr
explan_prob <- var_pr/t_var_pr
barplot(explan_prob)
t_var_pr <- sum(var_pr)
t_var_pr
var_pr
x
x0=USArrests
set.seed(1)
x5=USArrests[,2]+rnorm(50,0.01)
x=cbind(x0,new = x5)
x=scale(x)
y=1+1*x[,1]+2*x[,2]+3*x[,3]+4*x[,4]+5*x[,5]+rnorm(50)
pr.out=prcomp(x,scale=T)
head(pr.out,n=2)
var_pr <- pr.out$sdev^2
t_var_pr <- sum(var_pr)
explan_prob <- var_pr/t_var_pr
barplot(explan_prob)
var_pr
x
plot(explan_prob, type = 'l')
screeplot(pr.out)
library(pls)
set.seed(1)
pcr.fit=pcr(Salary~., data=Hitters,subset=train,scale=TRUE, validation="CV")
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit,x[test,],ncomp=7)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
summary(pcr.fit)
nrow(Hitters)
ncol(Hitters)
train = 1:200
test = -train
pcr.fit=pcr(Salary~., data=Hitters,subset=train,scale=TRUE, validation="CV")
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit,x[test,],ncomp=7)
x[test,]
pcr.pred=predict(pcr.fit,Hitters[test,],ncomp=7)
mean((pcr.pred-y.test)^2)
y.test = Hitters[test, "Salary"]
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
pcr.pred=predict(pcr.fit,Hitters[test,],ncomp=3)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=3)
summary(pcr.fit)
pcr.pred=predict(pcr.fit,Hitters[test,],ncomp=4)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=4)
summary(pcr.fit)
pcr.pred=predict(pcr.fit,Hitters[test,],ncomp=5)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=5)
summary(pcr.fit)
pcr.pred=predict(pcr.fit,Hitters[test,],ncomp=3)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=3)
summary(pcr.fit)

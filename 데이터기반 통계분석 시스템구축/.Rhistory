which(mean_conf > 0.3)),] # 20 넘는 increasing_rate와 mean_conf 가 큰 값들에 text를 입력해주기 위해 미리 설정
loc_conf <- mean_conf[c(which(is.finite(conf_result$increasing_rate) & conf_result$increasing_rate > 20),
which(mean_conf > 0.3))]
sum(conf_result$increasing_rate == Inf) # 102개가 Inf로 나온다
plot(mean_conf, conf_result$increasing_rate, ylim = c(-0.5, 27), xlim = c(-0.01, 0.5))
text(loc_conf+0.03, text_conf$increasing_rate, labels = text_conf$word, cex = 1, pos = 3) # x좌표를 보면 위 과정 이해 될 듯
abline(h=1, col='red')
# x, y 모두 exponential하기 때문에 log scale을 취해준다
# log0은 없기 때문에 아주 작은 수를 더해준다
plot(mean_conf + 1e-4, conf_result$increasing_rate + 1e-2, log = "xy", ylim = c(1e-2, 27), xlim = c(1e-4, 2)) # log = "xy"를 해주면 xy축 모두 로그스케일
text(loc_conf*exp(0.03), text_conf$increasing_rate, labels = text_conf$word, cex = 1, pos = 3)
abline(h = 1, col = 'red')
# Term Document Matrix 만들기 : 특정 Document 컬럼에 Term이 몇 번 나왔는지 나타내는 df
doc_list = data_list$n_gram
uniq_words <- unique(do.call('c', doc_list))
occur_vec_list <- lapply(doc_list, function(x) uniq_words %in% x)
dtm_mat = do.call('rbind', occur_vec_list) # list를 matrix 형으로 바꿔줬음
colnames(dtm_mat) <- uniq_words # uniq_words들의
dtm_mat[1:3, 1:3]
length(dtm_mat) # == nrow * ncol
# nrow(dtm_mat)
# ncol(dtm_mat)
refined_dtm_mat <- dtm_mat[, colSums(dtm_mat) != 0] # 단어 중 문서 전체에서 하나도 안 나온 것은 제거
refined_dtm_mat <- refined_dtm_mat[rowSums(dtm_mat) != 0,]
co_occur_mat <- t(refined_dtm_mat) %*% refined_dtm_mat # 행렬 곱을 통해 특정 단어가 나온 문서에서 다른 특정 단어가 나온 빈도수 표현 (마코브 체인 활용)
# 나오는 결과는 단어 X 단어 matrix
co_occur_mat[1:4, 1:4]
# co_occur_mat의 숫자의 강도를 power로 주고 sankey 그래프를 그리자
# 우선 matrix 크기를 줄일 것이다
## diag의 수가 빈도를 의미하기 때문에 diag가 너무 작은 것은 제거한다
inv = (diag(co_occur_mat) >= 150)
co_occur_mat1 <- co_occur_mat[inv, inv]
## 앞서 구한 confidence 비율 증가가 큰 단어들을 가져온다
idx = which(conf_result$increasing_rate[which(is.finite(conf_result$increasing_rate))] >= 5) # increasing_rate가 5보다 크고 유한인 경우만 사용
co_occur_mat2 <- co_occur_mat[idx, idx]
co_occurrence <- co_occur_mat1[-noIdx, -noIdx]
co_occurrence
# save(dfBP2, file = "dfBP.RData")
#============================================================================================================
load("dfBP.RData")
# Term Document Matrix 만들기 : 특정 Document 컬럼에 Term이 몇 번 나왔는지 나타내는 df
noun_list = nouns
uniq_words <- unique(do.call('c', noun_list))
occur_vec_list <- lapply(noun_list, function(x) uniq_words %in% x)
dtm_mat = do.call('rbind', occur_vec_list) # list를 matrix 형으로 바꿔줬음
colnames(dtm_mat) <- uniq_words # uniq_words들의
dtm_mat[1:7, 1:7]
length(dtm_mat) # == nrow * ncol
# nrow(dtm_mat)
# ncol(dtm_mat)
refined_dtm_mat <- dtm_mat[, colSums(dtm_mat) != 0] # 단어 중 문서 전체에서 하나도 안 나온 것은 제거
refined_dtm_mat <- refined_dtm_mat[rowSums(dtm_mat) != 0,]
co_occur_mat <- t(refined_dtm_mat) %*% refined_dtm_mat # 행렬 곱을 통해 특정 단어가 나온 문서에서 다른 특정 단어가 나온 빈도수 표현 (마코브 체인 활용)
# 나오는 결과는 단어 X 단어 matrix
co_occur_mat[1:7, 1:7]
# co_occur_mat의 숫자의 강도를 power로 주고 sankey 그래프를 그리자
# 우선 matrix 크기를 줄일 것이다
## diag의 수가 빈도를 의미하기 때문에 diag가 너무 작은 것은 제거한다
inv = (diag(co_occur_mat) >= 40)
co_occur_mat1 <- co_occur_mat[inv, inv]
co_occur_mat1[1:7, 1:7]
noIdx <- which(colnames(co_occur_mat1) %in% c("해", "후", "한", "의", "이", "장", "저", "적", '전', '제', '주', '중', '지',
'은', '을', '위', '월', '원', '세', '수', '로', '만', '명', '본', '분', '라', '데', '도', '두',
'들', '를', '기', '나', '날', '내', '대', '데', '개', '그', '때', '리', '화', '양', '들이',
'듯', '과', '드', '니', '바', '림', '얼', '거', '시', "호", "년", "것", "출처", "번", "속",
'amp', 'cm', 'com', 'gt', 'https', 'k', 'lt', 'm',
'q', 's', 'x', 'v', 'www', 'u', 'a', 'b', 'r',
'ne', 'l', 'e', 'd'))
co_occurrence <- co_occur_mat1[-noIdx, -noIdx]
co_occurrence
g = graph.adjacency(co_occurrence, weighted = T, mode = 'undirected') # 인접행렬 형태에서 igraph 만들기 편하게 해주는 함수
g = simplify(g) # loop나 다중간선 없게
wc = cluster_walktrap(g) # communities(densely connected subgraphs) 찾기
members = membership(wc)
network_list = igraph_to_networkD3(g, group = members) # igraph to d3 list
sankeyNetwork(Links = network_list$links, Nodes = network_list$nodes,
Source = "source", Target = "target",
Value = "value", NodeID = "name",
units = "TWh", fontSize = 20, nodeWidth = 20)
# Term Document Matrix 만들기 : 특정 Document 컬럼에 Term이 몇 번 나왔는지 나타내는 df
noun_list = nouns
noun_list
if(!require(OpenStreetMap)){install.packages("OpenStreetMap"); library(OpenStreetMap)}
library(ggmap)
install.packages("ggmap")
library(ggmap)
install.packages("tidyverse")
if(!require(OpenStreetMap)){install.packages("OpenStreetMap"); library(OpenStreetMap)}
install.packages("Rcpp")
if(!require(OpenStreetMap)){install.packages("OpenStreetMap"); library(OpenStreetMap)}
library(ggmap)
install.packages("stringi")
library(ggmap)
map = OpenStreetMap::openmap(upperLeft = c(43, 119),
lowerRight = c(33, 134), type = 'bing')
plot(map)
nm = c("osm", "mapbox", "stamen-toner",
"stamen-watercolor", "esri", "esri-topo",
"nps", "apple-iphoto", "osm-public-transport")
par(mfrow=c(3,3),  mar=c(0, 0, 0, 0), oma=c(0, 0, 0, 0))
for(i in 1:length(nm)){
map <- openmap(c(43,119),
c(33,134),
minNumTiles = 3,
type = nm[i])
plot(map, xlab = paste(nm[i]))
}
par(mfrow = c(1, 1))
map1 <- openmap(c(43.46,119.94),
c(33.22,133.98))
autoplot(map1) # 좌표 값도 보여줌
plot(map1)
abline(h = 38, col = 'blue') # 아무 일도 일어나지 않는다 openmap은 일반적인 plot과 좌표계가 다르기 때문이다
abline(h = 4500000, col = 'blue') # str(map1)을 통해 범위를 알 수 있다
str(map1)
map1$tiles[[1]]$projection
str(map1$tiles[[1]]$projection)
if(!require(sp)){install.packages("sp"); library(sp)} # Spatial Points
map_p <- openproj(map1, projection = CRS("+proj=longlat")) # 위경도 좌표계로 변했음
# +는 좌표계를 설정할 옵션 구분자
# CRS(Coordinate Reference System)
str(map_p)
autoplot(map_p)
plot(map_p)
abline(h = 38, col = 'blue')
map_p <- openproj(map1, projection =
CRS("+proj=utm +zone=52N + datum=WGS84"))
plot(map_p)
abline(h = 38, col = 'blue')
str(map_p)
# 이제 map_p에 line을 그을 수 없다. 그렇다면 점을 찍어서 잇자
## 데이터 프레임 만들기
a <- data.frame(lon = seq(100, 140, by=0.1), lat = 38); head(a)
## sp 클래스로 변환하기
sp::coordinates(a) = ~ lon + lat; head(a) # a has coords, bbox
str(a)
abline(h = 38, col = 'blue')
str(map_p)
# 이제 map_p에 line을 그을 수 없다. 그렇다면 점을 찍어서 잇자
## 데이터 프레임 만들기
a <- data.frame(lon = seq(100, 140, by=0.1), lat = 38); head(a)
## sp 클래스로 변환하기
sp::coordinates(a) = ~ lon + lat; head(a) # a has coords, bbox
str(a)
a@coords # slot 열 때는 @로 한다. $와 비슷한 역할
## projection을 설정하기
sp::proj4string(a) = "+proj=longlat" # map_p와 같게
str(a)
## 좌표계 변환하기
a_tf = spTransform(a,  CRS("+proj=utm +zone=52N + datum=WGS84"))  # map_p와 같게
str(a_tf)
# 지도위에 매핑하기
plot(map_p)
points(a_tf@coords[,1], a_tf@coords[,2], type='l', col='blue') # lon, lat으로 점 그리기 type = 'l'
# 지도 위에 파이차트 그리기
library(mapplots) # add.pie를 위해
map = openmap(upperLeft = c(43, 119),lowerRight = c(33, 134))
seoul_loc = geocode('Seoul') # 서울의 geocode를 받아옴(lon, lat)
coordinates(seoul_loc) = ~lon + lat # @coords를 lon과 lat 데이터로
proj4string(seoul_loc) = "+proj=longlat +datum=WGS84"
seoul_loc_Tf = spTransform(seoul_loc,
CRS(as.character(map$tiles[[1]]$projection)))
plot(map)
add.pie(z=1:2,labels = c('a','b'),
x = seoul_loc_Tf@coords[1],
y = seoul_loc_Tf@coords[2], radius = 100000)
# 범죄 데이터
data(crime)
head(crime, 3)
violent_crimes = subset(crime,
offense != "auto theft" &
offense != "theft" &
offense != "burglary")
violent_crimes$offense <- factor(violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder"))
violent_crimes = subset(violent_crimes,
-95.39681 <= lon & lon <= -95.34188 &
29.73631 <= lat & lat <=  29.78400)
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft")
HoustonMap + geom_point(aes(x = lon, y = lat, colour = offense, size = offense),
xlim = c(-95.39681, -95.34188),data = violent_crimes)
install.packages("panel.margin")
install.packages("panel.spacing")
install.packages("panel")
library(ggmap)
violent_crimes = subset(crime,
offense != "auto theft" &
offense != "theft" &
offense != "burglary")
violent_crimes$offense <- factor(violent_crimes$offense,
levels = c("robbery", "aggravated assault", "rape", "murder"))
violent_crimes = subset(violent_crimes,
-95.39681 <= lon & lon <= -95.34188 &
29.73631 <= lat & lat <=  29.78400)
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft")
panel.spacing
panel.margin
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft")
HoustonMap = qmap("Houston", zoom = 14, color = "bw", legend = "topleft")
HoustonMap + geom_point(aes(x = lon, y = lat, colour = offense, size = offense),
xlim = c(-95.39681, -95.34188),data = violent_crimes)
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft")
load('data/airport.Rdata')
head(airport_krjp)
map = ggmap(get_googlemap(center = c(lon=134, lat=36),
zoom = 5, maptype='roadmap', color='bw'))
map + geom_line(data=link_krjp,aes(x=lon,y=lat,group=group),
col='grey10',alpha=0.05) +
geom_point(data=airport_krjp[complete.cases(airport_krjp),],
aes(x=lon,y=lat, size=Freq), colour='black',alpha=0.5) +
scale_size(range=c(0,15))
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft")
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft", extend = "spacing")
HoustonMap = qmap("houston", zoom = 14, color = "bw", legend = "topleft", extend = "panel.spacing")
theme_set(theme_bw(16))
HoustonMap <- qmap("houston", zoom = 14, color = "bw",
extent = "device", legend = "topleft")
HoustonMap <- ggmap(
get_map("houston", zoom = 14, color = "bw"),
extent = "device", legend = "topleft"
)
library(grid)
# only violent crimes
violent_crimes <- subset(crime,
offense != "auto theft" &
offense != "theft" &
offense != "burglary"
)
# rank violent crimes
violent_crimes$offense <-
factor(violent_crimes$offense,
levels = c("robbery", "aggravated assault",
"rape", "murder")
)
# restrict to downtown
violent_crimes <- subset(violent_crimes,
-95.39681 <= lon & lon <= -95.34188 &
29.73631 <= lat & lat <= 29.78400
)
# get map and bounding box
theme_set(theme_bw(16))
HoustonMap <- qmap("houston", zoom = 14, color = "bw",
extent = "device", legend = "topleft")
HoustonMap <- ggmap(
get_map("houston", zoom = 14, color = "bw"),
extent = "device", legend = "topleft"
)
# the bubble chart
HoustonMap +
geom_point(aes(x = lon, y = lat, colour = offense, size = offense), data = violent_crimes) +
scale_colour_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
scale_size_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder"),
range = c(1.75,6)) +
guides(size = guide_legend(override.aes = list(size = 6))) +
theme(
legend.key.size = grid::unit(1.8,"lines"),
legend.title = element_text(size = 16, face = "bold"),
legend.text = element_text(size = 14)
) +
labs(colour = "Offense", size = "Offense")
# doing it with qmplot is even easier
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite",
color = offense, size = offense, legend = "topleft"
)
# or, with styling:
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite",
color = offense, size = offense, legend = "topleft"
) +
scale_colour_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
scale_size_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder"),
range = c(1.75,6)) +
guides(size = guide_legend(override.aes = list(size = 6))) +
theme(
legend.key.size = grid::unit(1.8,"lines"),
legend.title = element_text(size = 16, face = "bold"),
legend.text = element_text(size = 14)
) +
labs(colour = "Offense", size = "Offense")
# a contour plot
HoustonMap +
stat_density2d(aes(x = lon, y = lat, colour = offense),
size = 3, bins = 2, alpha = 3/4, data = violent_crimes) +
scale_colour_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
theme(
legend.text = element_text(size = 15, vjust = .5),
legend.title = element_text(size = 15,face="bold"),
legend.key.size = grid::unit(1.8,"lines")
)
# 2d histogram...
HoustonMap +
stat_bin2d(aes(x = lon, y = lat, colour = offense, fill = offense),
size = .5, bins = 30, alpha = 2/4, data = violent_crimes) +
scale_colour_discrete("Offense",
labels = c("Robery","Aggravated Assault","Rape","Murder"),
guide = FALSE) +
scale_fill_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
theme(
legend.text = element_text(size = 15, vjust = .5),
legend.title = element_text(size = 15,face="bold"),
legend.key.size = grid::unit(1.8,"lines")
)
# ... with hexagonal bins
HoustonMap +
stat_binhex(aes(x = lon, y = lat, colour = offense, fill = offense),
size = .5, binwidth = c(.00225,.00225), alpha = 2/4, data = violent_crimes) +
scale_colour_discrete("Offense",
labels = c("Robery","Aggravated Assault","Rape","Murder"),
guide = FALSE) +
scale_fill_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
theme(
legend.text = element_text(size = 15, vjust = .5),
legend.title = element_text(size = 15,face="bold"),
legend.key.size = grid::unit(1.8,"lines")
)
# changing gears (get a color map)
houston <- get_map("houston", zoom = 14)
HoustonMap <- ggmap(houston, extent = "device", legend = "topleft")
# a filled contour plot...
HoustonMap +
stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
size = 2, bins = 4, data = violent_crimes, geom = "polygon") +
scale_fill_gradient("Violent\nCrime\nDensity") +
scale_alpha(range = c(.4, .75), guide = FALSE) +
guides(fill = guide_colorbar(barwidth = 1.5, barheight = 10))
# ... with an insert
overlay <- stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
bins = 4, geom = "polygon", data = violent_crimes)
HoustonMap +
stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
bins = 4, geom = "polygon", data = violent_crimes) +
scale_fill_gradient("Violent\nCrime\nDensity") +
scale_alpha(range = c(.4, .75), guide = FALSE) +
guides(fill = guide_colorbar(barwidth = 1.5, barheight = 10)) +
inset(
grob = ggplotGrob(ggplot() + overlay +
scale_fill_gradient("Violent\nCrime\nDensity") +
scale_alpha(range = c(.4, .75), guide = FALSE) +
theme_inset()
),
xmin = attr(houston,"bb")$ll.lon +
(7/10) * (attr(houston,"bb")$ur.lon - attr(houston,"bb")$ll.lon),
xmax = Inf,
ymin = -Inf,
ymax = attr(houston,"bb")$ll.lat +
(3/10) * (attr(houston,"bb")$ur.lat - attr(houston,"bb")$ll.lat)
)
HoustonMap <- qmap("houston", zoom = 14, color = "bw",
extent = "device", legend = "topleft")
HoustonMap <- ggmap(
get_map("houston", zoom = 14, color = "bw"),
extent = "device", legend = "topleft"
)
# the bubble chart
HoustonMap +
geom_point(aes(x = lon, y = lat, colour = offense, size = offense), data = violent_crimes) +
scale_colour_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
scale_size_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder"),
range = c(1.75,6)) +
guides(size = guide_legend(override.aes = list(size = 6))) +
theme(
legend.key.size = grid::unit(1.8,"lines"),
legend.title = element_text(size = 16, face = "bold"),
legend.text = element_text(size = 14)
) +
labs(colour = "Offense", size = "Offense")
# doing it with qmplot is even easier
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite",
color = offense, size = offense, legend = "topleft"
)
# or, with styling:
qmplot(lon, lat, data = violent_crimes, maptype = "toner-lite",
color = offense, size = offense, legend = "topleft"
) +
scale_colour_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
scale_size_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder"),
range = c(1.75,6)) +
guides(size = guide_legend(override.aes = list(size = 6))) +
theme(
legend.key.size = grid::unit(1.8,"lines"),
legend.title = element_text(size = 16, face = "bold"),
legend.text = element_text(size = 14)
) +
labs(colour = "Offense", size = "Offense")
# a contour plot
HoustonMap +
stat_density2d(aes(x = lon, y = lat, colour = offense),
size = 3, bins = 2, alpha = 3/4, data = violent_crimes) +
scale_colour_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
theme(
legend.text = element_text(size = 15, vjust = .5),
legend.title = element_text(size = 15,face="bold"),
legend.key.size = grid::unit(1.8,"lines")
)
# 2d histogram...
HoustonMap +
stat_bin2d(aes(x = lon, y = lat, colour = offense, fill = offense),
size = .5, bins = 30, alpha = 2/4, data = violent_crimes) +
scale_colour_discrete("Offense",
labels = c("Robery","Aggravated Assault","Rape","Murder"),
guide = FALSE) +
scale_fill_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
theme(
legend.text = element_text(size = 15, vjust = .5),
legend.title = element_text(size = 15,face="bold"),
legend.key.size = grid::unit(1.8,"lines")
)
# ... with hexagonal bins
HoustonMap +
stat_binhex(aes(x = lon, y = lat, colour = offense, fill = offense),
size = .5, binwidth = c(.00225,.00225), alpha = 2/4, data = violent_crimes) +
scale_colour_discrete("Offense",
labels = c("Robery","Aggravated Assault","Rape","Murder"),
guide = FALSE) +
scale_fill_discrete("Offense", labels = c("Robery","Aggravated Assault","Rape","Murder")) +
theme(
legend.text = element_text(size = 15, vjust = .5),
legend.title = element_text(size = 15,face="bold"),
legend.key.size = grid::unit(1.8,"lines")
)
# changing gears (get a color map)
houston <- get_map("houston", zoom = 14)
HoustonMap <- ggmap(houston, extent = "device", legend = "topleft")
# a filled contour plot...
HoustonMap +
stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
size = 2, bins = 4, data = violent_crimes, geom = "polygon") +
scale_fill_gradient("Violent\nCrime\nDensity") +
scale_alpha(range = c(.4, .75), guide = FALSE) +
guides(fill = guide_colorbar(barwidth = 1.5, barheight = 10))
# ... with an insert
overlay <- stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
bins = 4, geom = "polygon", data = violent_crimes)
overlay <- stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
bins = 4, geom = "polygon", data = violent_crimes)
HoustonMap +
stat_density2d(aes(x = lon, y = lat, fill = ..level.., alpha = ..level..),
bins = 4, geom = "polygon", data = violent_crimes) +
scale_fill_gradient("Violent\nCrime\nDensity") +
scale_alpha(range = c(.4, .75), guide = FALSE) +
guides(fill = guide_colorbar(barwidth = 1.5, barheight = 10)) +
inset(
grob = ggplotGrob(ggplot() + overlay +
scale_fill_gradient("Violent\nCrime\nDensity") +
scale_alpha(range = c(.4, .75), guide = FALSE) +
theme_inset()
),
xmin = attr(houston,"bb")$ll.lon +
(7/10) * (attr(houston,"bb")$ur.lon - attr(houston,"bb")$ll.lon),
xmax = Inf,
ymin = -Inf,
ymax = attr(houston,"bb")$ll.lat +
(3/10) * (attr(houston,"bb")$ur.lat - attr(houston,"bb")$ll.lat)
)
if (!require(sp)) {install.packages('sp'); library(sp)}
if (!require(gstat)) {install.packages('gstat'); library(gstat)}
if (!require(automap)) {install.packages('automap'); library(automap)}
if (!require(rgdal)) {install.packages('rgdal'); library(rgdal)}
if (!require(e1071)) {install.packages('e1071'); library(e1071)}
if (!require(dplyr)) {install.packages('dplyr'); library(dplyr)}
if (!require(lattice)) {install.packages('lattice'); library(lattice)}
if (!require(viridis)) {install.packages('viridis'); library(viridis)}
seoul032823 <- read.csv ("data/seoul032823.csv")
head(seoul032823)
skorea <- raster::getData(name ="GADM", country= "KOR", level=2)  # https://gadm.org/download_country_v3.html
# skorea <- readRDS("data/KOR_adm2.rds")
head(skorea,2)
if (!require(broom)) {install.packages('broom'); library(broom)}
## Loading required package: broom
skorea <- broom::tidy(skorea)
## Regions defined for each Polygons
class(skorea)
## [1] "data.frame"
head(skorea,3)
ggplot() + geom_map(data= skorea, map= skorea,
aes(map_id=id,group=group),fill=NA, colour="black") +
geom_point(data=seoul032823, aes(LON, LAT, col = PM10),alpha=0.7) +
labs(title= "PM10 Concentration in Seoul Area at South Korea",
x="Longitude", y= "Latitude", size="PM10(microgm/m3)")
coordinates(seoul032823) <- ~LON+LAT
class(seoul032823)
LON.range <- c(126.5, 127.5)
LAT.range <- c(37, 38)
seoul032823.grid <- expand.grid(
LON = seq(from = LON.range[1], to = LON.range[2], by = 0.01),
LAT = seq(from = LAT.range[1], to = LAT.range[2], by = 0.01))
plot(seoul032823.grid)
points(seoul032823, pch= 16,col="red")
coordinates(seoul032823.grid)<- ~LON+LAT ## sp class
gridded(seoul032823.grid)<- T
plot(seoul032823.grid)
points(seoul032823, pch= 16,col="red")
seoul032823_OK <- autoKrige(formula = PM10~1,
input_data = seoul032823,
new_data = seoul032823.grid )
str(seoul032823_OK)
head(seoul032823_OK$krige_output)
head(seoul032823_OK$krige_output@coords, 2)
head(seoul032823_OK$krige_output@data$var1.pred,2)
myPoints <- data.frame(seoul032823)
myKorea <- data.frame(skorea)
myKrige <- data.frame(seoul032823_OK$krige_output@coords,
pred = seoul032823_OK$krige_output@data$var1.pred)
if(!require(viridis)){install.packages("viridis"); library(viridis)}
ggplot()+ theme_minimal() +
geom_tile(data = myKrige, aes(x= LON, y= LAT, fill = pred)) +
geom_map(data= myKorea, map= myKorea, aes(map_id=id,group=group),
fill=NA, colour="black") +
coord_cartesian(xlim= LON.range ,ylim= LAT.range) +
labs(title= "PM10 Concentration in Seoul Area at South Korea",
x="Longitude", y= "Latitude")+
theme(title= element_text(hjust = 0.5,vjust = 1,face= c("bold")))+
scale_fill_viridis(option="magma")
